{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YcByiP5Biho-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohanmad/machine-learning-exercises/blob/main/K_meansClustering_project_old_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copyright: Â© NexStream Technical Education, LLC**.  \n",
        "All rights reserved"
      ],
      "metadata": {
        "id": "y4Qweqd0-4G6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From scratch Implementation:  Part 1\n",
        "See the following cells as a guide to implementing Kmeans WITHOUT the use of any clustering library functions."
      ],
      "metadata": {
        "id": "YcByiP5Biho-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPqShbKzbGlE"
      },
      "outputs": [],
      "source": [
        "#Import relevant libraries\n",
        "import random\n",
        "import numpy as np\n",
        "from numpy.random import uniform\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt2\n",
        "from sklearn.datasets._samples_generator import make_blobs\n",
        "import seaborn as sns\n",
        "import doctest\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Construct a blob dataset of at least 4 clusters\n",
        "centers = None\n",
        "data, blob = make_blobs(n_samples=100, centers=centers, cluster_std=1)\n",
        "sns.scatterplot(x=None, y=None, hue=blob)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "09X5OUlAblxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define distance between a point and the dataset\n",
        "def calcdist(point, data):\n",
        "  return None"
      ],
      "metadata": {
        "id": "hYiLTLeEgJhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test your distance function\n",
        "testpoint = np.array([0,0])\n",
        "testdata = np.array([[1,2], [3,4], [5,12], [8,15]])\n",
        "print(calcdist(testpoint, testdata))\n",
        "testpoint2 = np.array([-1, 5])\n",
        "testdata2 = np.array([[3, 4], [9, 1], [-5, 2], [7, 20]])\n",
        "print(calcdist(testpoint2, testdata2))\n",
        "\n",
        "\n",
        "import doctest\n",
        "\"\"\"\n",
        "   >>> print(calcdist(testpoint, testdata))\n",
        "   [ 2.23606798  5.         13.         17.        ]\n",
        "   >>> print(calcdist(testpoint2, testdata2))\n",
        "   [ 4.12310563 10.77032961  5.         17.        ]\n",
        "\"\"\"\n",
        "\n",
        "doctest.testmod()"
      ],
      "metadata": {
        "id": "6ZhVBq-vhbVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implement the KMeans class\n",
        "\n",
        "<br>\n",
        "Algorithm:  \n",
        "\n",
        "1. Randomly place K markers (called centroids), one for each cluster.  \n",
        "\n",
        "2. Calc the distance of each point from the centroid, e.g. Euclidean\n",
        "We typically normalize the features that are used to define the dataset so that one parameter doesn't dominate the distance calc.  \n",
        "\n",
        "3. Assign each data point (object) to its closest centroid, creating a cluster.  \n",
        "\n",
        "4. Recalculate the position of the K centroids.  \n",
        "\n",
        "5. Repeat steps 1-4 until the centroids no longer move.  \n",
        "\n",
        "6. Calculate variances then Repeat steps 1-5 using K new randomly placed centroids for N user defined iterations are complete.  \n",
        "\n",
        "7. Assign the data to clusters which had the smallest saved variance.  \n",
        "\n",
        "<br>\n",
        "\n",
        "Constructor:  \n",
        "**def __init__(self, n_clusters=3, max_iter=800):**\n",
        "- Initialize instance variables for the number of clusters and max iterations\n",
        "\n",
        "\n",
        "Fit method:  \n",
        "**def fit(self, X_train):**    \n",
        "\n",
        "**1**. Randomly place K markers (called centroids), one for each cluster.  \n",
        "   - Compute min, max in X_train. Hints:   \n",
        "   https://numpy.org/doc/stable/reference/generated/numpy.minimum.html\n",
        "   https://numpy.org/doc/stable/reference/generated/numpy.maximum.html  \n",
        "   - Init centroids = uniform distributed between min and max for all n_clusters.  Hints:  \n",
        "   https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html\n",
        "   - Initialize iteration count = 0, and previous centroids = empty  \n",
        "\n",
        "- Loop over the max iterations *(while iteration < max_iter:)*\n",
        "     - Create an empty list of sorted points for each of the clusters.  Hint:  \n",
        "        *list_of_lists = [[] for _ in range(n)*, where n is the number of clusters\n",
        "     - Loop over the datapoints in X_train\n",
        "\n",
        "      **2**. Calc the distance from each data point to the centroid.  Hints:  \n",
        "      Call calcdist() to calculate distance between datapoint and each of the centroids and find the index of the centroid with that minimum distance.  \n",
        "      https://numpy.org/doc/stable/reference/generated/numpy.argmin.html\n",
        "\n",
        "      **3**. Assign each data point (object) to its closest centroid, creating a cluster.  Hint:  \n",
        "      https://numpy.org/doc/stable/reference/generated/numpy.append.html\n",
        "\n",
        "  **4**. Recalculate the position of the K centroids.  \n",
        "   - Update previous centroids = current centroids\n",
        "   - Calc the mean of the points assigned to the centroid cluster from step 3.  Make sure to check for nan's in case no points where assigned to the centroid, and in that case set the centroid to the previous centroid.\n",
        "\n",
        "  **5**. Increment *iteration*\n",
        "  \n",
        "  **6**. Calculate variances then Repeat steps 1-5 using K new randomly placed centroids for N user defined iterations are complete.  \n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Evaluate method:  \n",
        "**def evaluate(self, X):**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bzfTrsMPTbeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Kmeans algorithm\n",
        "class KMeans:\n",
        "  def __init__(self, n_clusters=3, max_iter=800):\n",
        "    self.n_clusters = None\n",
        "    self.max_iter = None\n",
        "  def fit(self, X_train):\n",
        "    # Randomly select centroid start points, uniformly distributed across the domain of the dataset\n",
        "    min_, max_ = None\n",
        "    self.centroids = None\n",
        "    # Initialize Variables\n",
        "    iteration = None\n",
        "    prev_centroids = None\n",
        "    while None\n",
        "      # Sort each data point, assigning to nearest centroid\n",
        "      sorted_points = None\n",
        "      for x in X_train:\n",
        "        dists = calcdist(x, self.centroids)\n",
        "        centroid_idx = None\n",
        "        sorted_points[centroid_idx].append(x)\n",
        "      # Push current centroids to previous, reassign centroids as mean of the points belonging to them\n",
        "      prev_centroids = None\n",
        "      self.centroids = None\n",
        "      for None in None:  # iterate through self.centroids\n",
        "        if None:  # Catch any np.nans, resulting from a centroid having no points\n",
        "            self.centroids[i] = prev_centroids[i]\n",
        "      iteration += 1\n",
        "\n",
        "  def evaluate(self, X):\n",
        "    centroids = []\n",
        "    centroid_idxs = []\n",
        "    for x in X:\n",
        "      dists = calcdist(x, self.centroids)\n",
        "      centroid_idx = None\n",
        "      centroids.append(None)\n",
        "      centroid_idxs.append(None)\n",
        "    return centroids, centroid_idx\n",
        "\n"
      ],
      "metadata": {
        "id": "ha_Qo4UKfWg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test your KMeans class constructor, fit, and evaluate functions\n",
        "\n",
        "kmeans = KMeans(n_clusters=centers)\n",
        "kmeans.fit(data)\n",
        "# View results\n",
        "class_centers, classification = kmeans.evaluate(data)\n",
        "sns.scatterplot(x=[X[0] for X in data],\n",
        "                y=[X[1] for X in data],\n",
        "                hue=blob,\n",
        "                style=classification,\n",
        "                palette=\"deep\",\n",
        "                legend=None\n",
        "                )\n",
        "plt.plot([x for x, _ in kmeans.centroids],\n",
        "         [y for _, y in kmeans.centroids],\n",
        "         '+',\n",
        "         markersize=15,\n",
        "         )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HhufPvSvwF-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test your code with at least 2 new data points placed somewhere in the sample space\n",
        "d1 = np.array([random.randint(0,10), random.randint(0,10)])\n",
        "\n",
        "sns.scatterplot(x=[X[0] for X in data],\n",
        "                y=[X[1] for X in data],\n",
        "                hue=blob,\n",
        "                style=classification,\n",
        "                palette=\"deep\",\n",
        "                legend=None\n",
        "                )\n",
        "plt.plot([x for x, _ in kmeans.centroids],\n",
        "         [y for _, y in kmeans.centroids],\n",
        "         '+',\n",
        "         markersize=15,\n",
        "         )\n",
        "plt.plot(d1[0], d1[1],\n",
        "         '.',\n",
        "         markersize=15,\n",
        "         color='black'\n",
        "         )\n",
        "plt.show()\n",
        "\n",
        "#Output the class they are assigned to"
      ],
      "metadata": {
        "id": "UbtRSgyt20eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means Sci-kit Learn Implementation:   Part 2\n",
        "Repeat Part 1, this time using skearn Kmeans functions.\n",
        "Compare your results."
      ],
      "metadata": {
        "id": "h2gdN3m8i8fJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "eKpPlSbUjf_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-means Performance Evaluation:  Part 3\n",
        "Evaluate the performance using Mean Silhouette Coefficient\n",
        "If the true cluster labels are unknown, the model itself can be used to evaluate performance using the Silhouette Coefficient.\n",
        "\n",
        "The Silhouette Coefficient range is [-1, 1], with best value == 1 and worst == -1.  A higher score indicates that the model has well defined and more dense clusters. Values close to 0 indicate overlapping clusters, while negative values usually indicate that data points have been assigned to the wrong clusters.\n",
        "Ref paper:  [Silhouettes: A graphical aid to the interpretation and validation of cluster analysis](https://www.sciencedirect.com/science/article/pii/0377042787901257?via%3Dihub)\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "># $s=\\frac{b-a}{max(b-a)}$\n",
        "\n",
        "\n",
        "<br>\n",
        "where:  \n",
        "\n",
        "- a: The average distance between one data point and all other points in the same cluster\n",
        "- b: The average distance between one data point and all other points in the next nearest cluster.\n",
        "\n",
        "\n",
        "Hint:  \n",
        "See https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html for more information on the silhouette score.\n"
      ],
      "metadata": {
        "id": "jwsHVXtmaXpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "tilexqyiaZb3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}